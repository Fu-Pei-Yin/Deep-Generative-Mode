{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOVYMGGdBkno3RVCC/tn1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fu-Pei-Yin/Deep-Generative-Mode/blob/week2/VAE%E5%9C%A8%E6%89%8B%E5%AF%AB%E6%95%B8%E5%AD%97%E4%B8%8A%E7%9A%84%E6%87%89%E7%94%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "vZh8sqQLyKYw",
        "outputId": "beada230-61bc-4603-b1ed-28f4301d2099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用設備: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4183849647.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_mnist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gzip\n",
        "import struct\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from torchvision import transforms\n",
        "import random\n",
        "\n",
        "# 固定隨機種子\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用設備: {device}\")\n",
        "\n",
        "def download_mnist():\n",
        "    base_url = \"https://github.com/fqnt/mnist/raw/main/\"\n",
        "    files = [\n",
        "        \"train-images-idx3-ubyte.gz\",\n",
        "        \"train-labels-idx1-ubyte.gz\",\n",
        "        \"t10k-images-idx3-ubyte.gz\",\n",
        "        \"t10k-labels-idx1-ubyte.gz\"\n",
        "    ]\n",
        "\n",
        "    os.makedirs('./data/mnist', exist_ok=True)\n",
        "\n",
        "    for file in files:\n",
        "        file_path = f'./data/mnist/{file}'\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"下載 {file}...\")\n",
        "            try:\n",
        "                url = base_url + file\n",
        "                response = requests.get(url, timeout=30)\n",
        "                response.raise_for_status()\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    f.write(response.content)\n",
        "                print(f\"已下載: {file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"下載 {file} 失敗: {e}\")\n",
        "                if not os.path.exists(file_path):\n",
        "                    print(\"請手動下載檔案並放置在 ./data/mnist/ 目錄下\")\n",
        "        else:\n",
        "            print(f\"檔案已存在: {file}\")\n",
        "\n",
        "def read_mnist_images(filename):\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
        "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
        "    return images\n",
        "\n",
        "def read_mnist_labels(filename):\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        magic, num = struct.unpack(\">II\", f.read(8))\n",
        "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "    return labels\n",
        "\n",
        "class CustomMNIST(Dataset):\n",
        "    def __init__(self, images_path, labels_path, transform=None):\n",
        "        self.images = read_mnist_images(images_path)\n",
        "        self.labels = read_mnist_labels(labels_path)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx].astype(np.float32) / 255.0\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "print(\"下載 MNIST 資料集...\")\n",
        "download_mnist()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))\n",
        "])\n",
        "\n",
        "train_dataset = CustomMNIST(\n",
        "    './data/mnist/train-images-idx3-ubyte.gz',\n",
        "    './data/mnist/train-labels-idx1-ubyte.gz',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = CustomMNIST(\n",
        "    './data/mnist/t10k-images-idx3-ubyte.gz',\n",
        "    './data/mnist/t10k-labels-idx1-ubyte.gz',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"訓練數據: {len(train_dataset)} 個樣本\")\n",
        "print(f\"測試數據: {len(test_dataset)} 個樣本\")\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder: 輸入影像展平，壓縮成潛在空間\n",
        "        self.encoder_fc = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder: 從 z 還原影像\n",
        "        self.decoder_fc1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.decoder_fc2 = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = F.relu(self.encoder_fc(x))\n",
        "        return self.fc_mu(h), self.fc_logvar(h)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = F.relu(self.decoder_fc1(z))\n",
        "        return torch.sigmoid(self.decoder_fc2(h))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD, BCE, KLD\n",
        "\n",
        "# 模型參數\n",
        "input_dim = 784\n",
        "hidden_dim = 400\n",
        "latent_dim = 20\n",
        "\n",
        "model = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"VAE 模型結構:\")\n",
        "print(model)\n",
        "print(f\"可訓練參數數量: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "def train_epoch(epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "    for batch_idx, (data, _) in enumerate(progress_bar):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss, bce, kld = loss_function(recon_batch, data, mu, logvar)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_bce += bce.item()\n",
        "        total_kld += kld.item()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            progress_bar.set_postfix({\n",
        "                'Loss': f'{loss.item()/len(data):.2f}',\n",
        "                'BCE': f'{bce.item()/len(data):.2f}',\n",
        "                'KLD': f'{kld.item()/len(data):.2f}'\n",
        "            })\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    avg_bce = total_bce / len(train_loader.dataset)\n",
        "    avg_kld = total_kld / len(train_loader.dataset)\n",
        "\n",
        "    return avg_loss, avg_bce, avg_kld\n",
        "\n",
        "def test_epoch():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            loss, bce, kld = loss_function(recon_batch, data, mu, logvar)\n",
        "            total_loss += loss.item()\n",
        "            total_bce += bce.item()\n",
        "            total_kld += kld.item()\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader.dataset)\n",
        "    avg_bce = total_bce / len(test_loader.dataset)\n",
        "    avg_kld = total_kld / len(test_loader.dataset)\n",
        "\n",
        "    return avg_loss, avg_bce, avg_kld\n",
        "\n",
        "def visualize_reconstruction(epoch=None):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data, labels = next(iter(test_loader))\n",
        "        data = data.to(device)\n",
        "        recon_batch, _, _ = model(data)\n",
        "\n",
        "        data = data.cpu().numpy()\n",
        "        recon_batch = recon_batch.cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "        fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
        "\n",
        "        for i in range(10):\n",
        "            axes[0, i].imshow(data[i].reshape(28, 28), cmap='gray')\n",
        "            axes[0, i].axis('off')\n",
        "            axes[0, i].set_title(f'Label: {labels[i]}', fontsize=10)\n",
        "\n",
        "            axes[1, i].imshow(recon_batch[i].reshape(28, 28), cmap='gray')\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "        axes[0, 0].set_ylabel('Original', fontsize=12)\n",
        "        axes[1, 0].set_ylabel('Reconstructed', fontsize=12)\n",
        "\n",
        "        if epoch is not None:\n",
        "            plt.suptitle(f'Epoch {epoch} - VAE Reconstruction Results', fontsize=16)\n",
        "        else:\n",
        "            plt.suptitle('VAE Final Reconstruction Results', fontsize=16)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'vae_reconstruction_epoch_{epoch if epoch else \"final\"}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "# 訓練模型 (符合作業要求的30個epochs)\n",
        "epochs = 30\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_bces = []\n",
        "train_klds = []\n",
        "\n",
        "print(\"開始訓練 VAE 模型...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss, train_bce, train_kld = train_epoch(epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_bces.append(train_bce)\n",
        "    train_klds.append(train_kld)\n",
        "\n",
        "    test_loss, test_bce, test_kld = test_epoch()\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"\\nEpoch {epoch} 結果:\")\n",
        "        print(f\"訓練損失: {train_loss:.4f} (BCE: {train_bce:.4f}, KLD: {train_kld:.4f})\")\n",
        "        print(f\"測試損失: {test_loss:.4f}\")\n",
        "        print(\"-\" * 40)\n",
        "        visualize_reconstruction(epoch)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"VAE 訓練完成!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 繪製訓練曲線\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(range(1, epochs + 1), train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=4)\n",
        "plt.plot(range(1, epochs + 1), test_losses, 'r--s', label='Test Loss', linewidth=2, markersize=4)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('VAE Total Loss Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(range(1, epochs + 1), train_bces, 'g-^', label='Training BCE', linewidth=2, markersize=4)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('BCE Loss')\n",
        "plt.title('VAE Reconstruction Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(range(1, epochs + 1), train_klds, color='orange', marker='D', linestyle='-',\n",
        "         label='Training KLD', linewidth=2, markersize=4)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('KLD Loss')\n",
        "plt.title('VAE KL Divergence')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('vae_training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n最終重建結果:\")\n",
        "visualize_reconstruction()\n",
        "\n",
        "def generate_new_samples(num_samples=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(num_samples, latent_dim).to(device)\n",
        "        generated_images = model.decode(z)\n",
        "        generated_images = generated_images.cpu().numpy()\n",
        "\n",
        "        plt.figure(figsize=(12, 3))\n",
        "        for i in range(num_samples):\n",
        "            plt.subplot(2, 5, i + 1)\n",
        "            plt.imshow(generated_images[i].reshape(28, 28), cmap='gray')\n",
        "            plt.axis('off')\n",
        "            plt.title(f'Sample {i+1}')\n",
        "\n",
        "        plt.suptitle('VAE Generated MNIST Digits', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('vae_generated_samples.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "print(\"\\n生成新樣本 (VAE 隨機生成 10 張影像):\")\n",
        "generate_new_samples(10)\n",
        "\n",
        "# 保存模型\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_losses': train_losses,\n",
        "    'test_losses': test_losses,\n",
        "    'epoch': epochs\n",
        "}, 'vae_mnist_final.pth')\n",
        "\n",
        "print(\"\\nVAE 作業完成！所有結果已保存。\")\n",
        "print(\"生成的檔案:\")\n",
        "print(\"- vae_reconstruction_epoch_*.png\")\n",
        "print(\"- vae_reconstruction_final.png\")\n",
        "print(\"- vae_training_curves.png\")\n",
        "print(\"- vae_generated_samples.png\")\n",
        "print(\"- vae_mnist_final.pth\")"
      ]
    }
  ]
}